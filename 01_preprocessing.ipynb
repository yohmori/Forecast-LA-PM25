{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Background of Excellence in Research Award (Phase II)"]},{"cell_type":"markdown","metadata":{},"source":["![Example Image](https://i.ibb.co/2WqHdXy/Phase-II-partner-logo-bar-v2.png)"]},{"cell_type":"markdown","metadata":{},"source":["Climate change is a globally relevant, urgent, and multi-faceted issue heavily impacting many industries and aspects of public life. Participants in Phase II will have the opportunity to examine the climate change from different perspectives. Participants will choose to explore one dataset among several, spanning sectors including healthcare, energy and environmental protection. Participants will also have opportunities to take deeper dives into their dataset and tackle a range of impactful real-world tasks.\n","\n","Phase II participants will be able to choose one of three research tracks to explore:\n","- ->US Environmental Protection Agency (EPA): weather, air pollutant, and census data\n","- MIT Critical Data: CDC county level COVID data\n","- Climate Change AI: Fine grained building energy usage data"]},{"cell_type":"markdown","metadata":{},"source":["Description of the data:\n","\n","This dataset represents daily air quality measurements in the United States for 2019 and 2020 in EPA’s Air Quality System (AQS, https://www.epa.gov/aqs) database in which both PM2.5 and ozone are measured concurrently.  These PM2.5 and ozone concentration data are joined with locational, meteorological, demographic information, and concentrations of other major air quality pollutants when available.  All of the data were downloaded from AQS with the exception of four demographic parameters (people of color, low income, linguistically isolated, and less than high school education) which come from EPA’s EJSCREEN tool (https://www.epa.gov/ejscreen).  These demographic parameters are at the Census \"block group\" level (area defined by the Census Bureau that usually has between 600 and 3,000 people) and listed in fractional units for the block group containing the monitor location. "]},{"cell_type":"markdown","metadata":{},"source":["# 2. Import Libraries, Define Functions"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-18T03:25:36.907767Z","iopub.status.busy":"2023-04-18T03:25:36.906918Z","iopub.status.idle":"2023-04-18T03:25:38.148342Z","shell.execute_reply":"2023-04-18T03:25:38.147067Z","shell.execute_reply.started":"2023-04-18T03:25:36.907716Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","\n","# set the default precision to one decimal place\n","pd.set_option('display.float_format', '{:.2f}'.format)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T03:25:39.067980Z","iopub.status.busy":"2023-04-18T03:25:39.067529Z","iopub.status.idle":"2023-04-18T03:25:39.095529Z","shell.execute_reply":"2023-04-18T03:25:39.094117Z","shell.execute_reply.started":"2023-04-18T03:25:39.067937Z"},"trusted":true},"outputs":[],"source":["def load_data():\n","    file_paths = []\n","    for dirname, _, filenames in os.walk('epa'):\n","        for filename in filenames:\n","            file_paths.append(os.path.join(dirname, filename))\n","    \n","    # Load Data\n","    air_2019 = pd.read_excel(file_paths[-1])\n","    air_2020 = pd.read_excel(file_paths[-2])\n","    \n","    # Specify STATE and COUNTY (Los Angeles and Riverside)\n","    air_LA_2019 = air_2019[(air_2019['STATE'] == 'California') & (air_2019['COUNTY'] == 'Los Angeles')]\n","    air_LA_2020 = air_2020[(air_2020['STATE'] == 'California') & (air_2020['COUNTY'] == 'Los Angeles')]\n","    \n","    air_RS_2019 = air_2019[(air_2019['STATE'] == 'California') & (air_2019['COUNTY'] == 'Riverside')]\n","    air_RS_2020 = air_2020[(air_2020['STATE'] == 'California') & (air_2020['COUNTY'] == 'Riverside')]\n","    \n","    # Merge 2019 and 2020 datasets\n","    df_LA_merged = pd.concat([air_LA_2019, air_LA_2020])\n","    df_RS_merged = pd.concat([air_RS_2019, air_RS_2020])\n","\n","    return df_LA_merged, df_RS_merged\n","\n","def preprocess(df, df_RS):\n","    # Change DATE column to pandas datetime\n","    df['datetime'] = pd.to_datetime(df['DATE'])\n","    # Sort data by datetime\n","    df_sorted = df.sort_values('datetime')\n","    # To tackle duplicates, group by datetime\n","    df_grouped = df_sorted.groupby('datetime').mean()\n","    \n","    # Drop unnecessary columns\n","    # Since we are only looking at a specific location, geographic data will be constant\n","    # Demographic data will also be constant\n","    # Other atmospheric data are too sparse with too many empty records, so we will drop them\n","    df_dropped = df_grouped.drop(['LATITUDE', 'LONGITUDE','PEOPLE_OF_COLOR_FRACTION',\n","                                  'LOW_INCOME_FRACTION', 'LINGUISTICALLY_ISOLATED_FRACTION',\n","                                  'LESS_THAN_HS_ED_FRACTION', 'LEAD_UG_PER_CUBIC_METER', 'BENZENE_PPBC',\n","                                  'WIND_DIRECTION', 'RELATIVE_HUMIDITY'], axis=1)\n","    \n","    # Preprocess/fill in data for SO2\n","    df_dropped = preprocess_so2(df_dropped)\n","    # Preprocess/fill in data for Temperature\n","    df_dropped = preprocess_temp(df_dropped, df_RS)\n","    \n","    # Select the columns with null values\n","    null_counts = df_dropped.isnull().sum()\n","    null_columns = null_counts[null_counts > 0].index\n","    # Impute missing values using SimpleImputer from sklearn.impute module. Here, we will use mean imputation for simplicity\n","    imputer = SimpleImputer(strategy='mean')\n","    # Apply mean imputation to the selected columns with null values\n","    df_dropped[null_columns] = imputer.fit_transform(df_dropped[null_columns])\n","    \n","    # Resample the DataFrame to include all dates and forward-fill missing values\n","    df_dropped = df_dropped.resample('D').ffill()\n","    # Fill in any remaining missing values with the previous value\n","    df_dropped = df_dropped.fillna(method='ffill')\n","    \n","    # Re-organize columns so that target variable is first column\n","    df_preprocessed = df_dropped.reindex(columns=['PM25_UG_PER_CUBIC_METER','TEMPERATURE_CELSIUS',\n","                                             'WIND_SPEED_METERS_PER_SECOND',\n","                                             'OZONE_PPM', 'NO2_PPB', 'CO_PPM', 'SO2_PPB'])\n","    \n","    return df_preprocessed\n","\n","def preprocess_so2(df):\n","    # Extract the 'NO2' and 'SO2' columns\n","    no2_values = df['NO2_PPB']\n","    so2_values = df['SO2_PPB']\n","\n","    # Standardize the 'NO2' and 'SO2' values\n","    scaler = StandardScaler()\n","    no2_values_norm = scaler.fit_transform(no2_values.values.reshape(-1, 1))\n","    so2_values_norm = scaler.fit_transform(so2_values.values.reshape(-1, 1))\n","\n","    # Replace missing 'SO2' values with the corresponding 'NO2' values\n","    so2_values_norm = pd.Series(so2_values_norm.flatten(), index=so2_values.index)\n","    no2_values_norm = pd.Series(no2_values_norm.flatten(), index=no2_values.index)\n","    so2_values_norm = so2_values_norm.fillna(no2_values_norm)\n","\n","    # Inverse transform the normalized 'SO2' values\n","    so2_values = scaler.inverse_transform(so2_values_norm.values.reshape(-1, 1))\n","\n","    # Update the 'SO2' column in the DataFrame\n","    df['SO2_PPB'] = so2_values\n","    \n","    return df\n","\n","def preprocess_temp(df, df_RS):\n","    df_RS['datetime'] = pd.to_datetime(df_RS['DATE'])\n","    df_RS_sorted = df_RS.sort_values('datetime')\n","    air_RS = df_RS_sorted.groupby('datetime').mean()\n","\n","    for i, _ in df[df['TEMPERATURE_CELSIUS'].isna()].iterrows():\n","        df.loc[i]['TEMPERATURE_CELSIUS'] = air_RS.loc[i]['TEMPERATURE_CELSIUS']\n","    \n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Load and Preprocess Data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T03:25:42.192770Z","iopub.status.busy":"2023-04-18T03:25:42.192356Z","iopub.status.idle":"2023-04-18T03:27:00.815050Z","shell.execute_reply":"2023-04-18T03:27:00.813704Z","shell.execute_reply.started":"2023-04-18T03:25:42.192735Z"},"trusted":true},"outputs":[],"source":["df_LA, df_RS = load_data()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T03:27:00.817484Z","iopub.status.busy":"2023-04-18T03:27:00.816965Z","iopub.status.idle":"2023-04-18T03:27:00.883971Z","shell.execute_reply":"2023-04-18T03:27:00.882742Z","shell.execute_reply.started":"2023-04-18T03:27:00.817449Z"},"trusted":true},"outputs":[],"source":["df_preprocessed = preprocess(df_LA, df_RS)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PM25_UG_PER_CUBIC_METER</th>\n","      <th>TEMPERATURE_CELSIUS</th>\n","      <th>WIND_SPEED_METERS_PER_SECOND</th>\n","      <th>OZONE_PPM</th>\n","      <th>NO2_PPB</th>\n","      <th>CO_PPM</th>\n","      <th>SO2_PPB</th>\n","    </tr>\n","    <tr>\n","      <th>datetime</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2019-01-01</th>\n","      <td>9.55</td>\n","      <td>6.60</td>\n","      <td>1.43</td>\n","      <td>0.03</td>\n","      <td>13.36</td>\n","      <td>0.45</td>\n","      <td>0.45</td>\n","    </tr>\n","    <tr>\n","      <th>2019-01-02</th>\n","      <td>9.55</td>\n","      <td>6.60</td>\n","      <td>1.43</td>\n","      <td>0.03</td>\n","      <td>13.36</td>\n","      <td>0.45</td>\n","      <td>0.45</td>\n","    </tr>\n","    <tr>\n","      <th>2019-01-03</th>\n","      <td>8.32</td>\n","      <td>10.55</td>\n","      <td>1.42</td>\n","      <td>0.03</td>\n","      <td>25.79</td>\n","      <td>0.62</td>\n","      <td>0.44</td>\n","    </tr>\n","    <tr>\n","      <th>2019-01-04</th>\n","      <td>12.60</td>\n","      <td>8.61</td>\n","      <td>2.04</td>\n","      <td>0.02</td>\n","      <td>27.74</td>\n","      <td>0.76</td>\n","      <td>0.61</td>\n","    </tr>\n","    <tr>\n","      <th>2019-01-05</th>\n","      <td>13.85</td>\n","      <td>8.25</td>\n","      <td>2.35</td>\n","      <td>0.03</td>\n","      <td>20.11</td>\n","      <td>0.65</td>\n","      <td>0.43</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2020-12-26</th>\n","      <td>18.26</td>\n","      <td>12.95</td>\n","      <td>0.85</td>\n","      <td>0.03</td>\n","      <td>18.31</td>\n","      <td>0.65</td>\n","      <td>0.18</td>\n","    </tr>\n","    <tr>\n","      <th>2020-12-27</th>\n","      <td>19.60</td>\n","      <td>14.05</td>\n","      <td>1.53</td>\n","      <td>0.03</td>\n","      <td>12.86</td>\n","      <td>0.38</td>\n","      <td>0.04</td>\n","    </tr>\n","    <tr>\n","      <th>2020-12-28</th>\n","      <td>2.80</td>\n","      <td>13.15</td>\n","      <td>1.53</td>\n","      <td>0.03</td>\n","      <td>9.59</td>\n","      <td>0.21</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2020-12-29</th>\n","      <td>4.82</td>\n","      <td>9.99</td>\n","      <td>1.53</td>\n","      <td>0.03</td>\n","      <td>15.78</td>\n","      <td>0.37</td>\n","      <td>0.10</td>\n","    </tr>\n","    <tr>\n","      <th>2020-12-30</th>\n","      <td>16.35</td>\n","      <td>11.31</td>\n","      <td>0.75</td>\n","      <td>0.03</td>\n","      <td>24.94</td>\n","      <td>1.00</td>\n","      <td>0.25</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>730 rows × 7 columns</p>\n","</div>"],"text/plain":["            PM25_UG_PER_CUBIC_METER  TEMPERATURE_CELSIUS  \\\n","datetime                                                   \n","2019-01-01                     9.55                 6.60   \n","2019-01-02                     9.55                 6.60   \n","2019-01-03                     8.32                10.55   \n","2019-01-04                    12.60                 8.61   \n","2019-01-05                    13.85                 8.25   \n","...                             ...                  ...   \n","2020-12-26                    18.26                12.95   \n","2020-12-27                    19.60                14.05   \n","2020-12-28                     2.80                13.15   \n","2020-12-29                     4.82                 9.99   \n","2020-12-30                    16.35                11.31   \n","\n","            WIND_SPEED_METERS_PER_SECOND  OZONE_PPM  NO2_PPB  CO_PPM  SO2_PPB  \n","datetime                                                                       \n","2019-01-01                          1.43       0.03    13.36    0.45     0.45  \n","2019-01-02                          1.43       0.03    13.36    0.45     0.45  \n","2019-01-03                          1.42       0.03    25.79    0.62     0.44  \n","2019-01-04                          2.04       0.02    27.74    0.76     0.61  \n","2019-01-05                          2.35       0.03    20.11    0.65     0.43  \n","...                                  ...        ...      ...     ...      ...  \n","2020-12-26                          0.85       0.03    18.31    0.65     0.18  \n","2020-12-27                          1.53       0.03    12.86    0.38     0.04  \n","2020-12-28                          1.53       0.03     9.59    0.21     0.00  \n","2020-12-29                          1.53       0.03    15.78    0.37     0.10  \n","2020-12-30                          0.75       0.03    24.94    1.00     0.25  \n","\n","[730 rows x 7 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df_preprocessed"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Output preprocessed dataframe, since loading raw every time is both time consuming as well as redundant\n","df_preprocessed.to_csv(\"data/df_preprocessed.csv\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
